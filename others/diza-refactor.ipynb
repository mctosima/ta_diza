{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import cv2 as cv\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "import copy\n",
    "import math\n",
    "import random\n",
    "from glob import glob\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "from torchvision import datasets, models\n",
    "from torchvision.utils import draw_bounding_boxes, make_grid\n",
    "from torchvision.transforms import transforms as T\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from pytorch_lightning import seed_everything, LightningModule, Trainer\n",
    "from sklearn.metrics import classification_report\n",
    "from pytorch_lightning.callbacks import (\n",
    "    EarlyStopping,\n",
    "    ModelCheckpoint,\n",
    "    LearningRateMonitor,\n",
    ")\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint\n",
    "from pytorch_lightning.loggers import WandbLogger\n",
    "from torchsummary import summary\n",
    "\n",
    "\n",
    "from pycocotools.coco import COCO\n",
    "from roboflow import Roboflow\n",
    "\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparation\n",
    "### Load Data from Roboflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(\"maskdetection-3\"):\n",
    "    print(\"Downloading dataset...\")\n",
    "    rf = Roboflow(api_key=\"RLpF5qnVG3u4wi0Hgkmg\")\n",
    "    project = rf.workspace(\"diza-febriyan-hasal\").project(\"maskdetection-tdrvn\")\n",
    "    dataset = project.version(3).download(\"coco\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Coret-coretan MCT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coco = COCO(os.path.join(\"maskdetection-3\", \"train\", \"_annotations.coco.json\"))\n",
    "anotasi_img = coco.loadAnns(coco.getAnnIds(0))\n",
    "print(anotasi_img)\n",
    "print(anotasi_img[0][\"bbox\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Reader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MaskDetection(Dataset):\n",
    "\n",
    "    \"\"\"\n",
    "    MaskDetection Datareader\n",
    "    Return:\n",
    "        - image pixels as tensor\n",
    "        - annotation as dictionary\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, root, split=\"train\"):\n",
    "        self.root = root\n",
    "        self.split = split\n",
    "        self.transforms = ToTensorV2()\n",
    "        self.coco = COCO(os.path.join(root, split, \"_annotations.coco.json\"))\n",
    "        self.ids = list(sorted(self.coco.imgs.keys()))\n",
    "\n",
    "    def __getitem__(self, idx: int):\n",
    "        id = self.ids[idx]\n",
    "        anotasi_img = self.coco.loadAnns(self.coco.getAnnIds(idx))\n",
    "        imgpath = self.coco.loadImgs(id)[0][\"file_name\"]\n",
    "        image = cv.imread(os.path.join(self.root, self.split, imgpath))\n",
    "        image = cv.normalize(image, None, 0, 255, cv.NORM_MINMAX)\n",
    "        # image = cv.cvtColor(image, cv.COLOR_BGR2RGB)\n",
    "        image = cv.cvtColor(image, cv.COLOR_RGB2GRAY)\n",
    "\n",
    "        image = self.transforms(image=image)[\"image\"]\n",
    "\n",
    "        bbox = [\n",
    "            anotasi_img[0][\"bbox\"][0],\n",
    "            anotasi_img[0][\"bbox\"][1],\n",
    "            anotasi_img[0][\"bbox\"][2],\n",
    "            anotasi_img[0][\"bbox\"][3],\n",
    "        ]\n",
    "        bbox = torch.as_tensor(bbox, dtype=torch.float32)\n",
    "\n",
    "        return image, bbox\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path = \"maskdetection-3\"\n",
    "train_dataset = MaskDetection(root=dataset_path, split=\"train\")\n",
    "val_dataset = MaskDetection(root=dataset_path, split=\"valid\")\n",
    "test_dataset = MaskDetection(root=dataset_path, split=\"test\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cek Ombak DataReader dan Data Loader\n",
    "> Sengaja di random, supaya gambarnya ganti-ganti\n",
    "\n",
    "- Bounding box digambar pakai `import matplotlib.patches as patches` supaya lebih gampang\n",
    "- Format bounding box mengikuti format asli dari COCO yaitu `[x, y, width, height]`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DataReader Cek"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_sample = train_dataset[random.randint(0, len(train_dataset))]\n",
    "image_pixels, bbox = image_sample\n",
    "print(type(image_pixels))\n",
    "\n",
    "plt.imshow(image_pixels.permute(1, 2, 0), cmap=\"gray\")\n",
    "\n",
    "rect = patches.Rectangle(\n",
    "    (bbox[0], bbox[1]),\n",
    "    bbox[2],\n",
    "    bbox[3],\n",
    "    linewidth=2,\n",
    "    edgecolor=\"r\",\n",
    "    facecolor=\"none\",\n",
    ")\n",
    "plt.gca().add_patch(rect)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Loader Cek\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=8,\n",
    "    shuffle=True,\n",
    "    num_workers=0,\n",
    "    collate_fn=lambda x: tuple(zip(*x)),\n",
    "    pin_memory=True,\n",
    ")\n",
    "\n",
    "print(len(train_loader))\n",
    "\n",
    "image, bbox = next(iter(train_loader))\n",
    "print(f\"Image shape: {image[2].shape}\")\n",
    "print(f\"Bbox sample: {bbox[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "grid_img = torchvision.utils.make_grid(image, 4, 2)\n",
    "plt.imshow(grid_img.permute(1, 2, 0))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pytorch Lightning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torchvision.models.detection.fasterrcnn_resnet50_fpn(weights=\"DEFAULT\")\n",
    "in_features = model.roi_heads.box_predictor.cls_score.in_features\n",
    "model.roi_heads.box_predictor = (\n",
    "    torchvision.models.detection.faster_rcnn.FastRCNNPredictor(in_features, 1)\n",
    ")\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class OurClass(LightningModule):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        # model architec\n",
    "        self.model = torchvision.models.detection.fasterrcnn_resnet50_fpn(\n",
    "            weights=\"DEFAULT\"\n",
    "        )\n",
    "        self.in_features = self.model.roi_heads.box_predictor.cls_score.in_features\n",
    "        self.model.roi_heads.box_predictor = (\n",
    "            self.torchvision.models.detection.faster_rcnn.FastRCNNPredictor(\n",
    "                self.in_features, 1\n",
    "            )\n",
    "        )\n",
    "\n",
    "        # param\n",
    "\n",
    "        # loss function\n",
    "\n",
    "        # evaluation metrics\n",
    "\n",
    "        # loss curve and accuracy curve\n",
    "\n",
    "        # load data\n",
    "\n",
    "        # split data\n",
    "\n",
    "    def forward(self, x):\n",
    "        return x\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        pass\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        pass\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        pass\n",
    "\n",
    "    def training_epoch_end(self, outputs):\n",
    "        pass\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        pass\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        pass\n",
    "\n",
    "    def validation_epoch_end(self, outputs):\n",
    "        pass"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('pytorch112_py38')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "176e86e6e21052ff89627b8e89e4f48b2aef17a8606feae6b75037084a2df81a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
