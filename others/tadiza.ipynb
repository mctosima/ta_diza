{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "# Package Dasar Python\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import copy\n",
    "import math\n",
    "\n",
    "# Package Pytorch dan Pendukungnya\n",
    "import torch\n",
    "import torchvision\n",
    "from torchvision import datasets, models\n",
    "from torchvision.utils import draw_bounding_boxes\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "from torchvision.transforms import transforms as T\n",
    "\n",
    "# Pytorch Lightning dkk\n",
    "from pytorch_lightning import LightningModule, Trainer\n",
    "\n",
    "\n",
    "# Package Utilities\n",
    "from pycocotools.coco import COCO\n",
    "from roboflow import Roboflow\n",
    "import albumentations as A"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Download Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "if not os.path.exists(\"maskdetection-3\"):\n",
    "    print(\"Downloading dataset...\")\n",
    "    rf = Roboflow(api_key=\"RLpF5qnVG3u4wi0Hgkmg\")\n",
    "    project = rf.workspace(\"diza-febriyan-hasal\").project(\"maskdetection-tdrvn\")\n",
    "    dataset = project.version(3).download(\"coco\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Reader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "def transformation():\n",
    "    transform = A.Compose([ToTensorV2()], bbox_params=A.BboxParams(format=\"coco\"))\n",
    "    return transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "class MaskDetection(Dataset):\n",
    "    def __init__(self, root, split=\"train\", transform=None, target_transform=None):\n",
    "        super().__init__()\n",
    "        self.root = root\n",
    "        self.split = split  # train, valid, test\n",
    "        self.coco = COCO(\n",
    "            os.path.join(root, split, \"_clean_annotations.coco.json\")\n",
    "        )  # annotatiosn stored here\n",
    "        self.ids = list(sorted(self.coco.imgs.keys()))\n",
    "        self.ids = [id for id in self.ids if (len(self._load_target(id)) > 0)]\n",
    "        self.transforms = transform\n",
    "\n",
    "    def _load_image(self, id: int):\n",
    "        path = self.coco.loadImgs(id)[0][\"file_name\"]\n",
    "        image = cv2.imread(os.path.join(self.root, self.split, path))\n",
    "        # image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        return image\n",
    "\n",
    "    def _load_target(self, id):\n",
    "        return self.coco.loadAnns(self.coco.getAnnIds(id))\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        id = self.ids[index]\n",
    "        image = self._load_image(id)\n",
    "        target = self._load_target(id)\n",
    "        target = copy.deepcopy(self._load_target(id))\n",
    "\n",
    "        boxes = [\n",
    "            t[\"bbox\"] + [t[\"category_id\"]] for t in target\n",
    "        ]  # required annotation format for albumentations\n",
    "\n",
    "        if self.transforms is not None:\n",
    "            transformed = self.transforms(image=image, bboxes=boxes)\n",
    "\n",
    "        image = transformed[\"image\"]\n",
    "        boxes = transformed[\"bboxes\"]\n",
    "\n",
    "        new_boxes = []  # convert from xywh to xyxy\n",
    "        for box in boxes:\n",
    "            xmin = box[0]\n",
    "            xmax = xmin + box[2]\n",
    "            ymin = box[1]\n",
    "            ymax = ymin + box[3]\n",
    "            new_boxes.append([xmin, ymin, xmax, ymax])\n",
    "\n",
    "        boxes = torch.tensor(new_boxes, dtype=torch.float32)\n",
    "\n",
    "        targ = {}  # here is our transformed target\n",
    "        targ[\"boxes\"] = boxes\n",
    "        targ[\"labels\"] = torch.tensor(\n",
    "            [t[\"category_id\"] for t in target], dtype=torch.int64\n",
    "        )\n",
    "        targ[\"image_id\"] = torch.tensor([t[\"image_id\"] for t in target])\n",
    "        targ[\"area\"] = (boxes[:, 3] - boxes[:, 1]) * (\n",
    "            boxes[:, 2] - boxes[:, 0]\n",
    "        )  # we have a different area\n",
    "        targ[\"iscrowd\"] = torch.tensor(\n",
    "            [t[\"iscrowd\"] for t in target], dtype=torch.int64\n",
    "        )\n",
    "        return image.div(255), targ  # scale images\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.ids)\n",
    "\n",
    "    def collate_fn(self, batch):\n",
    "        return tuple(zip(*batch))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PyTorch Lightning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "all_losses = []\n",
    "all_losses_dict = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "class ModuleFasterRCNN(LightningModule):\n",
    "    def __init__(self, model, lr=1e-3, batch_size=4, num_workers=4):\n",
    "        # init untuk mengatur variabel yang akan digunakan\n",
    "        super().__init__()\n",
    "\n",
    "        # model architec\n",
    "        self.model = model\n",
    "        self.lr = lr\n",
    "        self.batch_size = batch_size\n",
    "        self.num_workers = num_workers\n",
    "        self.dataset_path = \"maskdetection-3\"\n",
    "\n",
    "        # load data\n",
    "        self.train_dataset = MaskDetection(\n",
    "            root=self.dataset_path, split=\"train\", transform=transformation()\n",
    "        )\n",
    "        self.val_dataset = MaskDetection(\n",
    "            root=self.dataset_path, split=\"valid\", transform=transformation()\n",
    "        )\n",
    "        self.test_dataset = MaskDetection(\n",
    "            root=self.dataset_path, split=\"test\", transform=transformation()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        # digunakan untuk mengatur bagaimana model akan melakukan forward pass (selalu sama)\n",
    "        out = self.model(x)\n",
    "        return out\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        # digunakan untuk mengatur optimizer dan scheduler\n",
    "        optimizer = torch.optim.SGD(\n",
    "            self.model.parameters(),\n",
    "            lr=self.lr,\n",
    "            momentum=0.9,\n",
    "            weight_decay=1e-4,\n",
    "            nesterov=True,\n",
    "        )\n",
    "        # scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer, milestones=[16, 22], gamma=0.1)\n",
    "        return optimizer\n",
    "        # return {\"optimizer\": optimizer, \"lr_scheduler\": scheduler, \"monitor\": \"val_loss\"}\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        # memuat dataloader untuk train\n",
    "        train_loader = DataLoader(\n",
    "            self.train_dataset,\n",
    "            batch_size=self.batch_size,\n",
    "            shuffle=True,\n",
    "            num_workers=self.num_workers,\n",
    "            collate_fn=self.train_dataset.collate_fn,\n",
    "        )\n",
    "        return train_loader\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        # memuat cara untuk melakukan training\n",
    "        images, targets = batch\n",
    "        images = list(image for image in images)\n",
    "        targets = [{k: v for k, v in t.items()} for t in targets]\n",
    "\n",
    "        # menghitung loss\n",
    "        # Pada FasterRCNN, model akan mengembalikan loss ketika digunakan dalam mode training\n",
    "        # Mode Training: memberikan gambar dan target ke model\n",
    "        # Sementara itu, FasterRCNN akan mengembalikan bounding box apabila digunakan dalam mode\n",
    "        # Validasi dan testing, yaitu dengan memberikan hanya gambar saja ke model\n",
    "\n",
    "        loss_dict = self.model(images, targets)\n",
    "        losses = sum(loss for loss in loss_dict.values())\n",
    "        loss_dict_append = {k: v.item() for k, v in loss_dict.items()}\n",
    "        loss_value = losses.item()\n",
    "\n",
    "        all_losses.append(loss_value)  # coba dihapus\n",
    "        all_losses_dict.append(loss_dict_append)  # coba dihapus\n",
    "        self.log(\"train_loss\", losses, on_step=False, on_epoch=True, prog_bar=True, batch_size=self.batch_size)\n",
    "        return losses\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        # memuat dataloader untuk validasi\n",
    "        val_loader = DataLoader(\n",
    "            self.val_dataset,\n",
    "            batch_size=self.batch_size,\n",
    "            shuffle=False,\n",
    "            num_workers=self.num_workers,\n",
    "            collate_fn=self.val_dataset.collate_fn,\n",
    "        )\n",
    "        return val_loader\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        # memuat cara untuk melakukan validasi\n",
    "        images, targets = batch\n",
    "        images = list(image for image in images)\n",
    "        targets = [{k: v for k, v in t.items()} for t in targets]\n",
    "\n",
    "        output = self.model(images)\n",
    "        batch_iou_list = []\n",
    "        for i in range(len(output)):\n",
    "            pred_bbox = output[i][\"boxes\"][0].expand(1, 4)\n",
    "            pred_score = output[i][\"scores\"][0]\n",
    "            target_bbox = targets[i][\"boxes\"]\n",
    "\n",
    "            iou = torchvision.ops.box_iou(pred_bbox, target_bbox)\n",
    "\n",
    "        batch_iou = iou.mean().item()\n",
    "        print(f\"Batch IoUnya Adalah: {batch_iou}\")\n",
    "        self.log(\"val_iou\", batch_iou, on_step=False, on_epoch=True, prog_bar=True, batch_size=self.batch_size)\n",
    "        return batch_iou\n",
    "\n",
    "    def test_dataloader(self):\n",
    "        # memuat dataloader untuk testing\n",
    "        pass\n",
    "\n",
    "    def test_step(self, batch, batch_idx):\n",
    "        # memuat cara untuk melakukan testing\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "net = torchvision.models.detection.fasterrcnn_resnet50_fpn(weights=\"DEFAULT\")\n",
    "in_features = net.roi_heads.box_predictor.cls_score.in_features\n",
    "net.roi_heads.box_predictor = (\n",
    "    torchvision.models.detection.faster_rcnn.FastRCNNPredictor(in_features, 2)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=0.01s)\n",
      "creating index...\n",
      "index created!\n",
      "loading annotations into memory...\n",
      "Done (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "loading annotations into memory...\n",
      "Done (t=0.00s)\n",
      "creating index...\n",
      "index created!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit native Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name  | Type       | Params\n",
      "-------------------------------------\n",
      "0 | model | FasterRCNN | 41.3 M\n",
      "-------------------------------------\n",
      "41.1 M    Trainable params\n",
      "222 K     Non-trainable params\n",
      "41.3 M    Total params\n",
      "82.598    Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.011977434158325195,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Training",
       "rate": null,
       "total": null,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1027c080845f4cdaa447a8e662099c24",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Detected KeyboardInterrupt, attempting graceful shutdown...\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "module = ModuleFasterRCNN(model=net, lr=1e-3, batch_size=8, num_workers=8)\n",
    "trainer = Trainer(\n",
    "    accelerator=\"gpu\",\n",
    "    devices=1,\n",
    "    max_epochs=10,\n",
    "    num_sanity_val_steps=0,\n",
    "    precision=16,\n",
    "    enable_progress_bar=True,\n",
    ")\n",
    "trainer.fit(module)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "176e86e6e21052ff89627b8e89e4f48b2aef17a8606feae6b75037084a2df81a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
